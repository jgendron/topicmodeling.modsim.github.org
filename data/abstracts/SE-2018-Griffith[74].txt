Branches of the military are wasting time and money by duplicating efforts for proprietary scripted training systems. Training simulations offer tremendous promise in reducing costs and increasing realism but fail to achieve either aim. Efforts to create intelligent agents have been undertaken, but often are constrained to one simulation environment, leading to limited success. Standardization has failed, due to the fact that competing companies cling to their own solution as the Òbest and only wayÓ. The Multi-level Universal Specification for Intelligent Characters (MUSIC) provides a standard that participating simulation systems (PSS) can adopt to gain access to intelligent characters that can act within their environment. MUSIC will not require each participating cognitive system (PCS) to code in any particular programming language, but will provide rules of when and how to display situations to trainees within a standalone or federated simulation. Each simulation, regardless of its fidelity, will be able to leverage aspects of MUSIC to enhance training. By specifying things like Levels of Detail (LoD), simulations can automatically adjust based on the current training need and their capabilities. For instance, a Semi-Automated Forces (SAF) system or a birdÕs eye view simulation of a village may only need to show basic details, whereas first person 3D simulations might require an elaborate set of animations. This paper discusses the benefits of multiple levels of detail and explores different examples of how MUSIC can be deployed as a foundation for adaptable and scalable training solution that focuses finite investment dollars and maximizes returns. 